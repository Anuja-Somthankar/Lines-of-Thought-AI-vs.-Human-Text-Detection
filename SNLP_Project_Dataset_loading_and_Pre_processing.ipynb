{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "PVrLdZXHAhL0",
    "outputId": "92eddce6-434d-4577-c2fc-8885e2e76ee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp39-cp39-win_amd64.whl.metadata (8.3 kB)\n",
      "Downloading sentencepiece-0.2.0-cp39-cp39-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 991.5/991.5 kB 15.5 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install spacy\n",
    "# !pip install datasets\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install transformers==3.2.0\n",
    "# !pip install transformers[sentencepiece]\n",
    "# !pip install sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ORm6IjReEHHj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anuja\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import concurrent.futures\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from transformers import DistilBertTokenizer, AlbertTokenizer, BertTokenizer\n",
    "from transformers import AlbertForSequenceClassification, DistilBertForSequenceClassification, BertForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uoEpUMMjEo9T",
    "outputId": "3409adb0-b771-44dd-ccfe-8f34ca159d05"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anuja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\anuja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6_OBzHHAQ4R",
    "outputId": "cfa72209-4e6d-4aeb-9481-ea3bfe1769b8"
   },
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Jinyan1/COLING_2025_MGT_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yq_fSYBBAyvN",
    "outputId": "d1601ad2-b30c-43f7-f2ba-ff262ac596a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'source', 'sub_source', 'lang', 'model', 'label', 'text'],\n",
       "        num_rows: 610767\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'source', 'sub_source', 'lang', 'model', 'label', 'text'],\n",
       "        num_rows: 261758\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "4vj36ZORBt_G"
   },
   "outputs": [],
   "source": [
    "training_dataset = ds[\"train\"]\n",
    "train_dataset = training_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "02cXISTdCERP",
    "outputId": "8060264e-9d06-4f13-aa57-e2560746e503"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hitler plan succession power structure death s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bush administration turned attention iraq argu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best pedi pho attentive rush time come vega co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m mv loch seaforth passenger sailing month tes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malta participated eurovision song contest son...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  hitler plan succession power structure death s...      1\n",
       "1  bush administration turned attention iraq argu...      0\n",
       "2  best pedi pho attentive rush time come vega co...      0\n",
       "3  m mv loch seaforth passenger sailing month tes...      0\n",
       "4  malta participated eurovision song contest son...      0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset:  610767\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset[['text', 'label']]\n",
    "print(\"Length of the dataset: \", len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_batch(batch_texts):\n",
    "    processed_batch = []\n",
    "    for text in batch_texts:\n",
    "        text = text.lower()\n",
    "        doc = nlp(text)\n",
    "        tokens = []\n",
    "        for token in doc:\n",
    "            if token.is_alpha and not token.is_stop:\n",
    "                tokens.append(lemmatizer.lemmatize(token.text))\n",
    "        processed_batch.append(' '.join(tokens))\n",
    "    return processed_batch\n",
    "\n",
    "def preprocess_text_parallel(dataset):\n",
    "    batch_size = 1000\n",
    "    n = len(dataset)\n",
    "    processed_texts = []\n",
    "    batches = []\n",
    "    for i in range(0, n, batch_size):\n",
    "        batch = dataset['text'][i:i+batch_size].tolist()\n",
    "        batches.append(batch)\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(process_text_batch, batches)\n",
    "        \n",
    "    for batch in results:\n",
    "        processed_texts.extend(batch)\n",
    "    \n",
    "    dataset['text'] = processed_texts\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = preprocess_text_parallel(train_dataset) # 175m 4.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "True    610767\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_dataset['label'] == cleaned_dataset['label']).value_counts() # Checking if order was preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned dataset\n",
    "cleaned_dataset.to_csv('cleaned_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization for the BERT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = pd.read_csv('cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anuja\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\anuja\\.cache\\huggingface\\hub\\models--albert-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\anuja\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\anuja\\.cache\\huggingface\\hub\\models--huawei-noah--TinyBERT_General_4L_312D. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "albert_tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "tinybert_tokenizer = BertTokenizer.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_texts = [str(text) for text in cleaned_dataset['text'].values if text is not None]\n",
    "DB_inputs = distilbert_tokenizer(cleaned_texts, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "AB_inputs = albert_tokenizer(cleaned_texts, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "TB_inputs = tinybert_tokenizer(cleaned_texts, padding=True, truncation=True, max_length=512, return_tensors='pt') #56m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor(cleaned_dataset['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([610767, 512])\n",
      "torch.Size([610767, 512])\n",
      "torch.Size([610767, 512])\n",
      "torch.Size([610767])\n"
     ]
    }
   ],
   "source": [
    "print(DB_inputs['input_ids'].shape)\n",
    "print(AB_inputs['input_ids'].shape)\n",
    "print(TB_inputs['input_ids'].shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenized inputs and labels\n",
    "torch.save(DB_inputs, 'intermediates/DB_inputs.pt')\n",
    "torch.save(AB_inputs, 'intermediates/AB_inputs.pt')\n",
    "torch.save(TB_inputs, 'intermediates/TB_inputs.pt')\n",
    "torch.save(labels, 'intermediates/labels.pt')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
