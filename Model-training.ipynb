{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vishal Perumal\\anaconda3\\envs\\gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import DistilBertModel, AdamW, AutoModel, ElectraModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.inputs['input_ids'][idx]\n",
    "        attention_mask = self.inputs['attention_mask'][idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTMClassifier(nn.Module):\n",
    "    def __init__(self, tinybert, cnn_out_channels=64, lstm_hidden_dim=64, num_classes=2):\n",
    "        super(CNNLSTMClassifier, self).__init__()\n",
    "        self.tinybert = tinybert\n",
    "        self.cnn = nn.Conv1d(in_channels=768, out_channels=cnn_out_channels, kernel_size=3, padding=1)\n",
    "        self.lstm = nn.LSTM(cnn_out_channels, lstm_hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(lstm_hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.set_grad_enabled(self.tinybert.training):\n",
    "            distilbert_output = self.tinybert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            embeddings = distilbert_output.last_hidden_state.permute(0, 2, 1)  # (batch, embed_dim, seq_len)\n",
    "        \n",
    "        cnn_out = self.cnn(embeddings)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(cnn_out.permute(0, 2, 1))  # (batch, seq_len, lstm_hidden_dim)\n",
    "        \n",
    "        logits = self.fc(lstm_out[:, -1, :])  # Use last hidden state for classification\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTMClassifier(nn.Module):\n",
    "    def __init__(self, bert, in_channels, cnn_out_channels=64, lstm_hidden_dim=64, num_classes=2):\n",
    "        super(CNNLSTMClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.cnn = nn.Conv1d(in_channels=in_channels, out_channels=cnn_out_channels, kernel_size=3, padding=1)\n",
    "        self.lstm = nn.LSTM(cnn_out_channels, lstm_hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(lstm_hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.set_grad_enabled(self.bert.training):\n",
    "            bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            embeddings = bert_output.last_hidden_state.permute(0, 2, 1)  # (batch, embed_dim, seq_len)\n",
    "        \n",
    "        cnn_out = self.cnn(embeddings)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(cnn_out.permute(0, 2, 1))  # (batch, seq_len, lstm_hidden_dim)\n",
    "        \n",
    "        logits = self.fc(lstm_out[:, -1, :])  # Use last hidden state for classification\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('cleaned_dataset.csv')\n",
    "dev_dataset = pd.read_csv('cleaned_dev_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=1, accumulation_steps=10, device='cuda'):\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for i, batches in enumerate(tqdm(dataloader)):\n",
    "            input_ids = batches['input_ids'].to(device)\n",
    "            attention_mask = batches['attention_mask'].to(device)\n",
    "            labels = batches['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    print(\"Classification Report:\\n\")\n",
    "    with torch.no_grad():\n",
    "        for batches in tqdm(dataloader):\n",
    "            input_ids = batches['input_ids'].to(device)\n",
    "            attention_mask = batches['attention_mask'].to(device)\n",
    "            labels = batches['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    report = classification_report(true_labels, predictions, digits=4)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    print(\"Classification Report:\\n\")\n",
    "    with torch.no_grad():\n",
    "        for batches in tqdm(dataloader):\n",
    "            input_ids = batches['input_ids'].to(device)\n",
    "            attention_mask = batches['attention_mask'].to(device)\n",
    "            labels = batches['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    report = classification_report(true_labels, predictions, digits=4)\n",
    "    print(report)\n",
    "    return predictions, true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anuja\\AppData\\Local\\Temp\\ipykernel_2508\\3470213625.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_DB_inputs = torch.load('intermediates/DB_inputs.pt')\n",
      "C:\\Users\\anuja\\AppData\\Local\\Temp\\ipykernel_2508\\3470213625.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dev_DB_inputs = torch.load('intermediates/DB_dev_inputs.pt')\n",
      "C:\\Users\\anuja\\AppData\\Local\\Temp\\ipykernel_2508\\3470213625.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_DB_inputs = torch.load('intermediates/DB_test_inputs.pt')\n",
      "C:\\Users\\anuja\\AppData\\Local\\Temp\\ipykernel_2508\\3470213625.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_labels = torch.load('intermediates/labels.pt')\n",
      "C:\\Users\\anuja\\AppData\\Local\\Temp\\ipykernel_2508\\3470213625.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dev_labels = torch.load('intermediates/labels_dev.pt')\n",
      "C:\\Users\\anuja\\AppData\\Local\\Temp\\ipykernel_2508\\3470213625.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_labels = torch.load('intermediates/labels_test.pt')\n"
     ]
    }
   ],
   "source": [
    "train_DB_inputs = torch.load('intermediates/DB_inputs.pt')\n",
    "dev_DB_inputs = torch.load('intermediates/DB_dev_inputs.pt')\n",
    "test_DB_inputs = torch.load('intermediates/DB_test_inputs.pt')\n",
    "\n",
    "train_labels = torch.load('intermediates/labels.pt')\n",
    "dev_labels = torch.load('intermediates/labels_dev.pt')\n",
    "test_labels = torch.load('intermediates/labels_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_custom_dataset = CustomDataset(inputs=train_DB_inputs, labels=train_labels)\n",
    "dev_custom_dataset = CustomDataset(inputs=dev_DB_inputs, labels=dev_labels)\n",
    "test_custom_dataset = CustomDataset(inputs=test_DB_inputs, labels=test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_custom_dataset, batch_size=10, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_custom_dataset, batch_size=10)\n",
    "test_dataloader = DataLoader(test_custom_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNLSTMClassifier(\n",
       "  (bert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cnn): Conv1d(768, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (lstm): LSTM(64, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB_model = CNNLSTMClassifier(distilbert, in_channels=768)\n",
    "DB_model.train()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(DB_model.parameters(), lr=2e-5) #learing rate used by baseline from COLING 2025\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "DB_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61077 [00:00<?, ?it/s]c:\\Users\\Vishal Perumal\\anaconda3\\envs\\gpu\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:403: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "100%|██████████| 61077/61077 [5:02:40<00:00,  3.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.2886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DB_model = train_model(DB_model, train_dataloader, criterion, optimizer, num_epochs=1, accumulation_steps=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(DB_model, 'models/DB_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anuja\\AppData\\Local\\Temp\\ipykernel_27884\\4132632868.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  DB_model = torch.load('models/DB_model.pt')\n"
     ]
    }
   ],
   "source": [
    "DB_model = torch.load('models/DB_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26176 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26176/26176 [1:22:24<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9033    0.8553    0.8786     98328\n",
      "           1     0.9157    0.9449    0.9300    163430\n",
      "\n",
      "    accuracy                         0.9113    261758\n",
      "   macro avg     0.9095    0.9001    0.9043    261758\n",
      "weighted avg     0.9110    0.9113    0.9107    261758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(DB_model, dev_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7395/7395 [23:32<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8106    0.6062    0.6937     34675\n",
      "           1     0.7156    0.8749    0.7873     39266\n",
      "\n",
      "    accuracy                         0.7489     73941\n",
      "   macro avg     0.7631    0.7406    0.7405     73941\n",
      "weighted avg     0.7601    0.7489    0.7434     73941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DB_preds, DB_true_labels = test_model(DB_model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TinyBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_TB_inputs = torch.load('intermediates/TB_inputs.pt')\n",
    "dev_TB_inputs = torch.load('intermediates/TB_dev_inputs.pt')\n",
    "test_TB_inputs = torch.load('intermediates/TB_test_inputs.pt')\n",
    "\n",
    "train_labels = torch.load('intermediates/labels.pt')\n",
    "dev_labels = torch.load('intermediates/labels_dev.pt')\n",
    "test_labels = torch.load('intermediates/labels_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_custom_dataset = CustomDataset(inputs=train_TB_inputs, labels=train_labels)\n",
    "dev_custom_dataset = CustomDataset(inputs=dev_TB_inputs, labels=dev_labels)\n",
    "test_custom_dataset = CustomDataset(inputs=test_TB_inputs, labels=test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_custom_dataset, batch_size=10, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_custom_dataset, batch_size=10)\n",
    "test_dataloader = DataLoader(test_custom_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinybert = AutoModel.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vishal Perumal\\anaconda3\\envs\\gpu\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNLSTMClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 312)\n",
       "      (token_type_embeddings): Embedding(2, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-3): 4 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=1200, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1200, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cnn): Conv1d(312, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (lstm): LSTM(64, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TB_model = CNNLSTMClassifier(tinybert, in_channels=312)\n",
    "TB_model.train()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(TB_model.parameters(), lr=2e-5) #learing rate used by baseline from COLING 2025\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "TB_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61077/61077 [2:51:55<00:00,  5.92it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.3766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TB_model = train_model(TB_model, train_dataloader, criterion, optimizer, num_epochs=1, accumulation_steps=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(TB_model, 'models/TB_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_model = torch.load('models/TB_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26176/26176 [26:23<00:00, 16.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8366    0.8328    0.8347     98328\n",
      "           1     0.8997    0.9021    0.9009    163430\n",
      "\n",
      "    accuracy                         0.8761    261758\n",
      "   macro avg     0.8681    0.8674    0.8678    261758\n",
      "weighted avg     0.8760    0.8761    0.8760    261758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(TB_model, dev_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7395/7395 [03:43<00:00, 33.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7583    0.5596    0.6440     34675\n",
      "           1     0.6842    0.8425    0.7551     39266\n",
      "\n",
      "    accuracy                         0.7098     73941\n",
      "   macro avg     0.7212    0.7010    0.6995     73941\n",
      "weighted avg     0.7189    0.7098    0.7030     73941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TB_preds, TB_true_labels = test_model(TB_model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_EL_inputs = torch.load('intermediates/EL_inputs.pt')\n",
    "dev_EL_inputs = torch.load('intermediates/EL_dev_inputs.pt')\n",
    "test_EL_inputs = torch.load('intermediates/EL_test_inputs.pt')\n",
    "\n",
    "train_labels = torch.load('intermediates/labels.pt')\n",
    "dev_labels = torch.load('intermediates/labels_dev.pt')\n",
    "test_labels = torch.load('intermediates/labels_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_custom_dataset = CustomDataset(inputs=train_EL_inputs, labels=train_labels)\n",
    "dev_custom_dataset = CustomDataset(inputs=dev_EL_inputs, labels=dev_labels)\n",
    "test_custom_dataset = CustomDataset(inputs=test_EL_inputs, labels=test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_custom_dataset, batch_size=10, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_custom_dataset, batch_size=10)\n",
    "test_dataloader = DataLoader(test_custom_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra = ElectraModel.from_pretrained('google/electra-small-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vishal Perumal\\anaconda3\\envs\\gpu\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNLSTMClassifier(\n",
       "  (bert): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cnn): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (lstm): LSTM(64, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EL_model = CNNLSTMClassifier(electra, in_channels=256)\n",
    "EL_model.train()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(EL_model.parameters(), lr=2e-5) #learing rate used by baseline from COLING 2025\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "EL_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61077/61077 [2:16:53<00:00,  7.44it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.3171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EL_model = train_model(EL_model, train_dataloader, criterion, optimizer, num_epochs=1, accumulation_steps=10, device=device) #136m 53.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(EL_model, 'models/EL_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26176/26176 [19:31<00:00, 22.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9291    0.6536    0.7674     98328\n",
      "           1     0.8231    0.9700    0.8906    163430\n",
      "\n",
      "    accuracy                         0.8511    261758\n",
      "   macro avg     0.8761    0.8118    0.8290    261758\n",
      "weighted avg     0.8629    0.8511    0.8443    261758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(EL_model, dev_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7395/7395 [05:31<00:00, 22.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8379    0.3740    0.5171     34675\n",
      "           1     0.6287    0.9361    0.7522     39266\n",
      "\n",
      "    accuracy                         0.6725     73941\n",
      "   macro avg     0.7333    0.6550    0.6347     73941\n",
      "weighted avg     0.7268    0.6725    0.6420     73941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AB_preds, AB_true_labels = test_model(EL_model, test_dataloader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
